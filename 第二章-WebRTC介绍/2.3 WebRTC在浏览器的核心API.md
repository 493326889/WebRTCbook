# 2.3 WebRTCåœ¨æµè§ˆå™¨çš„æ ¸å¿ƒAPI
WebRTCåœ¨æµè§ˆå™¨ä¸­ï¼Œæœ‰3ä¸ªæ ¸å¿ƒå¯¹è±¡ï¼ŒMediaStream, PeerConnection, DataChannelã€‚å…¶ä¸­MediaStreamæ˜¯ä¸€ä¸ªåª’ä½“æµå¯¹è±¡ï¼Œç”¨äºæ ‡è¯†è·å–åˆ°çš„åª’ä½“æµä¿¡æ¯ï¼›PeerConnectionæ˜¯WebRTC P2Pä¼ è¾“çš„è¿æ¥å¯¹è±¡ï¼›DataChannelæ˜¯æ•°æ®é€šé“å¯¹è±¡ã€‚    

## 2.3.1 MediaStream   

MediaStreamå°è£…äº†ä¸€å¥—APIï¼Œå¯ä»¥æ‹¥æœ‰å¯¹ä»æ‘„åƒå¤´ï¼Œéº¦å…‹é£è·å–åˆ°çš„åª’ä½“æµçš„æ“ä½œæƒé™ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡MediaDevices.getUserMedia()æ¥è·å–åˆ°æ‘„åƒå¤´ï¼Œéº¦å…‹é£çš„åª’ä½“æµå¯¹è±¡ã€‚
````
// é€šè¿‡constraintsæŒ‡æ˜éœ€è¦è·å–çš„åª’ä½“æºæ•°æ®ï¼Œconstraintsè¿˜æœ‰å¾ˆå¤šå…¶ä»–é…ç½®å‚æ•°å“¦ï½åé¢ä¼šè¯¦ç»†è®²è§£
const constraints = {
  audio: true,
  video: true
};
try {
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    console.log(stream);
  } catch (e) {
    handleError(e);
  }
````   
è¾“å‡ºç»“æœï¼š
 ![å›¾ç‰‡1-01](../images/2-03-01.png)        

å˜é‡streamåˆ™æ˜¯è·å–åˆ°æ˜¯ä¸€ä¸ªMediaStreamå¯¹è±¡ï¼Œä¸€ä¸ªMediaStreamå¯¹è±¡å¯ä»¥æœ‰0åˆ°å¤šä¸ªMediaStreamTrackç»„æˆï¼Œä¸€ä¸ªMediaStreamTrackä»£è¡¨ä¸€è·¯éŸ³é¢‘è½¨é“æˆ–è€…è§†é¢‘è½¨é“ã€‚    
**è¡¥å……mediaStreamç»“æ„å›¾**       

æ¯ä¸ªMediaStreamå¯¹è±¡éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„idæ¥è¡¨ç¤ºï¼Œå¯ä»¥é€šè¿‡MediaStreamå¯¹è±¡idå±æ€§æ¥å–åˆ°å€¼ã€‚MediaStreamä¹Ÿæä¾›äº†endedå±æ€§æ¥è¡¨ç¤ºè¯¥åª’ä½“æµå¯¹è±¡æ˜¯å¦å·²ç»ç»“æŸã€‚   

MediaStreamäº‹ä»¶å¤„ç†ï¼š   
* MediaStream.onaddtrackï¼šå½“å¯¹ç«¯çš„åª’ä½“è½¨é“ä¿¡æ¯è¢«è®¾ç½®å®Œæˆï¼Œè§¦å‘çš„äº‹ä»¶ã€‚
* MediaStream.onendedï¼š åª’ä½“è½¨é“åª’ä½“æµç»“æŸ
* MediaStream.onremovetrack ï¼šå½“å¯¹ç«¯çš„åª’ä½“è½¨é“ä¿¡æ¯è¢«ç§»é™¤ï¼Œè§¦å‘çš„äº‹ä»¶ã€‚ 

MediaStreamæ ¸å¿ƒæ–¹æ³•ï¼š   
* MediaStream.addTrack() : å°†trackæ·»åŠ åˆ°MediaStreamä¸­ã€‚  
* MediaStream.clone(): å…‹éš†
* MediaStream.getTracks() : è·å–è¯¥MediaStreamä¸‹çš„æ‰€æœ‰åª’ä½“è½¨é“ã€‚
* MediaStream.getAudioTracks() : è·å–è¯¥MediaStreamä¸‹çš„æ‰€æœ‰éŸ³é¢‘åª’ä½“è½¨é“ã€‚
* MediaStream.getTrackById() : è·å–è¯¥MediaStreamä¸‹çš„æŸä¸€Idçš„åª’ä½“è½¨é“ã€‚
* MediaStream.getVideoTracks() : è·å–è¯¥MediaStreamä¸‹çš„æ‰€æœ‰è§†é¢‘åª’ä½“è½¨é“ã€‚
* MediaStream.removeTrack() : åˆ é™¤è¯¥MediaStreamä¸‹çš„åª’ä½“è½¨é“ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡MediaStream.getTracks()è·å–åˆ°æ¯ä¸ªMediaStreamä¸‹çš„trackæ•°ç»„ã€‚   
 ![å›¾ç‰‡1-01](../images/2-03-02.png)  
ä¸€ä¸ªMediaStreamTrackæœ‰2ç§ç”Ÿå‘½å‘¨æœŸçŠ¶æ€ï¼šliveä»¥åŠendedã€‚liveä»£è¡¨å½“å‰è½¨é“çš„åª’ä½“æºè¢«æ¿€æ´»ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœæ˜¯é™éŸ³æˆ–è€…é»‘å±ï¼Œå…¶çŠ¶æ€ä¾ç„¶æ˜¯liveã€‚å½“åª’ä½“æºå…³é—­æ—¶ï¼ŒçŠ¶æ€åˆ™æ˜¯endedã€‚

MediaStreamTrackå±æ€§ï¼š  
* MediaStreamTrack.enabled   
* MediaStreamTrack.id   
* MediaStreamTrack.kind   
* MediaStreamTrack.label   
* MediaStreamTrack.muted   
* MediaStreamTrack.readonly    
* MediaStreamTrack.readyState    
* MediaStreamTrack.remote    

MediaStreamTrackäº‹ä»¶å¤„ç†ï¼š
* MediaStreamTrack.onstarted   
* MediaStreamTrack.onmute   
* MediaStreamTrack.onunmute   
* MediaStreamTrack.onoverconstrained
* MediaStreamTrack.oneended

MediaStreamTrackæ ¸å¿ƒæ–¹æ³•ï¼š 

* MediaStream.getConstraints() 
* MediaStream.applyConstraints()
* MediaStream.getSettings()  
* MediaStream.getCapabilities()  
* MediaStream.clone()  
* MediaStream.stop()  

åœ¨è°ƒç”¨getUserMediaå¯ä»¥é€šè¿‡å‚æ•°ä¼ å…¥constraintsæ¥è®¾ç½®ä½ åˆ°MediaStreamå‚æ•°ã€‚æ¯”å¦‚è§†é¢‘çš„åˆ†è¾¨ç‡ï¼Œå¸§ç‡ç­‰ã€‚    
````
 const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
  video:  {
    frameRate: {min: 20},
    width: {min: 640, ideal: 1280},
    height: {min: 480, ideal: 720},
    aspectRatio: 3/2
  }
});
````   
* width: è®¾ç½®åˆ†è¾¨ç‡å®½åº¦ï¼Œå¯é€šè¿‡min, maxè®¾ç½®æœ€å°æœ€å¤§å€¼   
* height: è®¾ç½®åˆ†è¾¨ç‡é«˜åº¦ï¼Œå¯é€šè¿‡min, maxè®¾ç½®æœ€å°æœ€å¤§å€¼  
* frameRate: è®¾ç½®å¸§ç‡   
* aspectRatio: å®½é«˜æ¯”  
* facingMode: é•œå¤´æœå‘ï¼Œæœ‰4ç§å€¼ï¼Œåˆ†åˆ«ä¸ºï¼š1ï¼Œuserï¼ŒæŒ‡æ­£å¯¹ç€ç”¨æˆ·ï¼Œç±»ä¼¼æ‰‹æœºçš„å‰ç½®æ‘„åƒå¤´; 2ï¼Œenvironment, ç±»ä¼¼æ‰‹æœºçš„åç½®æ‘„åƒå¤´ï¼›3ï¼Œleft, ä½äºå·¦ä¾§ï¼›4ï¼Œright,ä½äºå³ä¾§ã€‚    

ç®€è€Œè¨€ä¹‹ï¼ŒMediaStreamå°±æ˜¯ä¸€ä¸ªéŸ³è§†é¢‘åª’ä½“æ•°æ®çš„æè¿°å¯¹è±¡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡MediaDevices.getUserMedia()æ¥è·å–åˆ°æœ¬æœºéŸ³è§†é¢‘è®¾å¤‡é‡‡é›†åˆ°çš„åª’ä½“æ•°æ®ï¼Œå¹¶é€šè¿‡PeerConnectionæˆ–è€…DataChannelä¼ è¾“ç»™å¯¹ç«¯ç”¨æˆ·ã€‚åä¹‹ï¼Œå¯¹ç«¯ç”¨æˆ·é€šè¿‡PeerConnectionæˆ–è€…DataChannelè·å–åˆ°éŸ³è§†é¢‘åª’ä½“æ•°æ®ï¼Œä¹Ÿå¯ä»¥é€šè¿‡MediaStreamå¯¹è±¡æ¥è¡¨ç¤ºã€‚    


## 2.3.2 RTCPeerConnection   
RTCPeerConnectionç”¨æ¥è¡¨ç¤ºä¸€ä¸ªWebRTCå®æ—¶åª’ä½“è¿æ¥çš„å¯¹è±¡ï¼Œè¯¥æ¥å£æä¾›äº†åˆ›å»ºï¼Œä¿æŒï¼Œç›‘æ§ï¼Œå…³é—­è¿æ¥çš„æ–¹æ³•çš„å®ç°ã€‚
 ![å›¾ç‰‡1-01](../images/2-03-03.png)  
æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢ä»£ç åˆå§‹åŒ–ä¸€ä¸ªRTCPeerConnectionå¯¹è±¡ã€‚
````
const peerConnection = new RTCPeerConnection();
````  
å½“é€šè®¯åŒæ–¹äº’ç›¸ç”Ÿæˆä¸€ä¸ªRTCPeerConnectionå¯¹è±¡åï¼Œé€šè¿‡SDP(RTCSessionDescription)äº¤æ¢ï¼Œä»¥åŠiceè¿æ¥å»ºç«‹ï¼ŒåŒæ–¹çš„è¿æ¥é€šé“å°±å»ºç«‹å®Œæˆã€‚Aå°†é€šè¿‡getUserMediaè·å–åˆ°çš„MediaStream trackï¼Œè°ƒç”¨addTrackæ–¹æ³•ã€‚Bé€šè¿‡ç›‘å¬onAddTrackæ–¹æ³•ï¼Œå°±å¯ä»¥ç›‘å¬åˆ°å¯¹ç«¯åª’ä½“è¢«æ·»åŠ çš„å›è°ƒï¼Œæ¥ç€å°†onAddTrackæ–¹æ³•å‚æ•°è¿”å›çš„trackå¯¹è±¡èµ‹å€¼ç»™video/audioçš„srcObjectï¼Œå°±å¯ä»¥æ’­æ”¾å¯¹ç«¯çš„åª’ä½“æµäº†ã€‚å…·ä½“ä»£ç å¦‚ä¸‹ï¼š      

index.html
````
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description" content="WebRTC code samples">
    <meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1">
    <title>Peer connection</title>
</head>

<body>

<div id="container">
    <video id="localVideo" playsinline autoplay muted></video>
    <video id="remoteVideo" playsinline autoplay></video>

    <div class="box">
        <button id="startButton">Start</button>
        <button id="callButton">Call</button>
        <button id="hangupButton">Hang Up</button>
    </div>

    <div class="box">
        <span>SDP Semantics:</span>
        <select id="sdpSemantics">
            <option selected value="">Default</option>
            <option value="unified-plan">Unified Plan</option>
            <option value="plan-b">Plan B</option>
        </select>
    </div>

<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script src="js/main.js" async></script>
</body>
</html>

````
js/mian.js    
````
const startButton = document.getElementById('startButton');
const callButton = document.getElementById('callButton');
const hangupButton = document.getElementById('hangupButton');
callButton.disabled = true;
hangupButton.disabled = true;
startButton.addEventListener('click', start);
callButton.addEventListener('click', call);
hangupButton.addEventListener('click', hangup);

let startTime;
const localVideo = document.getElementById('localVideo');
const remoteVideo = document.getElementById('remoteVideo');

localVideo.addEventListener('loadedmetadata', function() {
  console.log(`Local video videoWidth: ${this.videoWidth}px,  videoHeight: ${this.videoHeight}px`);
});

remoteVideo.addEventListener('loadedmetadata', function() {
  console.log(`Remote video videoWidth: ${this.videoWidth}px,  videoHeight: ${this.videoHeight}px`);
});

remoteVideo.addEventListener('resize', () => {
  console.log(`Remote video size changed to ${remoteVideo.videoWidth}x${remoteVideo.videoHeight}`);
  // We'll use the first onsize callback as an indication that video has started
  // playing out.
  if (startTime) {
    const elapsedTime = window.performance.now() - startTime;
    console.log('Setup time: ' + elapsedTime.toFixed(3) + 'ms');
    startTime = null;
  }
});

let localStream;
let pc1;
let pc2;
const offerOptions = {
  offerToReceiveAudio: 1,
  offerToReceiveVideo: 1
};

function getName(pc) {
  return (pc === pc1) ? 'pc1' : 'pc2';
}

function getOtherPc(pc) {
  return (pc === pc1) ? pc2 : pc1;
}

async function start() {
  console.log('Requesting local stream');
  startButton.disabled = true;
  try {
    const stream = await navigator.mediaDevices.getUserMedia({audio: true, video: true});
    console.log('Received local stream');
    localVideo.srcObject = stream;
    localStream = stream;
    callButton.disabled = false;
  } catch (e) {
    alert(`getUserMedia() error: ${e.name}`);
  }
}

function getSelectedSdpSemantics() {
  const sdpSemanticsSelect = document.querySelector('#sdpSemantics');
  const option = sdpSemanticsSelect.options[sdpSemanticsSelect.selectedIndex];
  return option.value === '' ? {} : {sdpSemantics: option.value};
}

async function call() {
  callButton.disabled = true;
  hangupButton.disabled = false;
  console.log('Starting call');
  startTime = window.performance.now();
  const videoTracks = localStream.getVideoTracks();
  const audioTracks = localStream.getAudioTracks();
  if (videoTracks.length > 0) {
    console.log(`Using video device: ${videoTracks[0].label}`);
  }
  if (audioTracks.length > 0) {
    console.log(`Using audio device: ${audioTracks[0].label}`);
  }
  const configuration = getSelectedSdpSemantics();
  console.log('RTCPeerConnection configuration:', configuration);
  pc1 = new RTCPeerConnection(configuration);
  console.log('Created local peer connection object pc1');
  pc1.addEventListener('icecandidate', e => onIceCandidate(pc1, e));
  pc2 = new RTCPeerConnection(configuration);
  console.log('Created remote peer connection object pc2');
  pc2.addEventListener('icecandidate', e => onIceCandidate(pc2, e));
  pc1.addEventListener('iceconnectionstatechange', e => onIceStateChange(pc1, e));
  pc2.addEventListener('iceconnectionstatechange', e => onIceStateChange(pc2, e));
  pc2.addEventListener('track', gotRemoteStream);

  localStream.getTracks().forEach(track => pc1.addTrack(track, localStream));
  console.log('Added local stream to pc1');

  try {
    console.log('pc1 createOffer start');
    const offer = await pc1.createOffer(offerOptions);
    await onCreateOfferSuccess(offer);
  } catch (e) {
    onCreateSessionDescriptionError(e);
  }
}

function onCreateSessionDescriptionError(error) {
  console.log(`Failed to create session description: ${error.toString()}`);
}async function onCreateOfferSuccess(desc) {
  console.log(`Offer from pc1\n${desc.sdp}`);
  console.log('pc1 setLocalDescription start');
  try {
    await pc1.setLocalDescription(desc);
    onSetLocalSuccess(pc1);
  } catch (e) {
    onSetSessionDescriptionError();
  }

  console.log('pc2 setRemoteDescription start');
  try {
    await pc2.setRemoteDescription(desc);
    onSetRemoteSuccess(pc2);
  } catch (e) {
    onSetSessionDescriptionError();
  }

  console.log('pc2 createAnswer start');
  // Since the 'remote' side has no media stream we need
  // to pass in the right constraints in order for it to
  // accept the incoming offer of audio and video.
  try {
    const answer = await pc2.createAnswer();
    await onCreateAnswerSuccess(answer);
  } catch (e) {
    onCreateSessionDescriptionError(e);
  }
}

function onSetLocalSuccess(pc) {
  console.log(`${getName(pc)} setLocalDescription complete`);
}

function onSetRemoteSuccess(pc) {
  console.log(`${getName(pc)} setRemoteDescription complete`);
}

function onSetSessionDescriptionError(error) {
  console.log(`Failed to set session description: ${error.toString()}`);
}

function gotRemoteStream(e) {
  if (remoteVideo.srcObject !== e.streams[0]) {
    remoteVideo.srcObject = e.streams[0];
    console.log('pc2 received remote stream');
  }
}

async function onCreateAnswerSuccess(desc) {
  console.log(`Answer from pc2:\n${desc.sdp}`);
  console.log('pc2 setLocalDescription start');
  try {
    await pc2.setLocalDescription(desc);
    onSetLocalSuccess(pc2);
  } catch (e) {
    onSetSessionDescriptionError(e);
  }
  console.log('pc1 setRemoteDescription start');
  try {
    await pc1.setRemoteDescription(desc);
    onSetRemoteSuccess(pc1);
  } catch (e) {
    onSetSessionDescriptionError(e);
  }
}

async function onIceCandidate(pc, event) {
  try {
    await (getOtherPc(pc).addIceCandidate(event.candidate));
    onAddIceCandidateSuccess(pc);
  } catch (e) {
    onAddIceCandidateError(pc, e);
  }
  console.log(`${getName(pc)} ICE candidate:\n${event.candidate ? event.candidate.candidate : '(null)'}`);
}

function onAddIceCandidateSuccess(pc) {
  console.log(`${getName(pc)} addIceCandidate success`);
}

function onAddIceCandidateError(pc, error) {
  console.log(`${getName(pc)} failed to add ICE Candidate: ${error.toString()}`);
}

function onIceStateChange(pc, event) {
  if (pc) {
    console.log(`${getName(pc)} ICE state: ${pc.iceConnectionState}`);
    console.log('ICE state change event: ', event);
  }
}

function hangup() {
  console.log('Ending call');
  pc1.close();
  pc2.close();
  pc1 = null;
  pc2 = null;
  hangupButton.disabled = true;
  callButton.disabled = false;
}
````
å…³äºSDPäº¤æ¢ä»¥åŠICEé€šé“å»ºç«‹ï¼Œå°†åœ¨åç»­ç« èŠ‚è¯¦ç»†ä»‹ç»ã€‚    
  
## 2.3.3 RTCDataChannel    
é™¤äº†éŸ³è§†é¢‘åª’ä½“æµä¹‹å¤–ï¼ŒWebRTCè¿˜æä¾›äº†å…¶ä»–ç±»å‹çš„å®æ—¶é€šè®¯èƒ½åŠ›ï¼ŒRTCDataChannelã€‚RTCDataChannelæ˜¯ä¸€ä¸ªç”¨äºå»ºç«‹å¯¹ç«¯ä¹‹é—´åŒå‘æ•°æ®é€šé“çš„å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒå½“æˆä¸€ä¸ªç±»ä¼¼websocketçš„åŒå‘æ•°æ®ä¼ è¾“é€šé“ï¼Œä¸åŒä¹‹å¤„åœ¨äºRTCDataChannelé»˜è®¤é‡‡ç”¨åŸºäºUDPçš„SCTPä¼ è¾“åè®®æ¥, å…·å¤‡UDPä½å»¶è¿Ÿï¼Œé«˜ååé‡ï¼Œä¹Ÿæ‹¥æœ‰ç±»TCPçš„å¯é ä¼ è¾“ç­‰ç‰¹ç‚¹ã€‚RTCDataChannelæœ‰å¾ˆå¤šæ½œfåœ¨çš„åº”ç”¨ç‰¹å¾ï¼Œæ¯”å¦‚æ¸¸æˆï¼Œè¿œç¨‹æ¡Œé¢ï¼Œå®æ—¶é€šè®¯ï¼Œæ–‡ä»¶ä¼ è¾“ï¼Œåˆ†å¸ƒå¼ç½‘ç»œã€‚  
æˆ‘ä»¬å¯ä»¥é€šè¿‡RTCPeerConnectionå®šcreateDataChannelæ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªRTCDataChannelé€šé“ã€‚å¹¶ä¸”é€šè¿‡sendæ–¹æ³•ï¼Œæ¥å‘é€æ•°æ®ç»™å¯¹ç«¯ï¼Œé€šè¿‡onmessageç›‘å¬å¯¹ç«¯ä¼ é€’è¿‡æ¥çš„æ•°æ®ã€‚

````
const localConnection = new RTCPeerConnection(servers);
const remoteConnection = new RTCPeerConnection(servers);
const sendChannel =
  localConnection.createDataChannel('sendDataChannel');

remoteConnection.ondatachannel = (event) => {
  receiveChannel = event.channel;
  receiveChannel.onmessage = onReceiveMessage;
  receiveChannel.onopen = onReceiveChannelStateChange;
  receiveChannel.onclose = onReceiveChannelStateChange;
};

function onReceiveMessage(event) {
  document.querySelector("textarea#send").value = event.data;
}

document.querySelector("button#send").onclick = () => {
  var data = document.querySelector("textarea#send").value;
  sendChannel.send(data);
};
````